{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Covid Tweet BERT.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b10e31783b804939a15bafc75b8f7789":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b25b3ddd60df44bebe21b1b42027c43c","IPY_MODEL_1c9b26049cd0464ea54c787e809f5df0","IPY_MODEL_f7e5976f3c8c4b458e6f259081a54dfc"],"layout":"IPY_MODEL_127f955811f14f9e902c81aedc6da9a4"}},"b25b3ddd60df44bebe21b1b42027c43c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_594722e3b7734c56b32bcb022c83a6c6","placeholder":"​","style":"IPY_MODEL_1d03e25713f0434ead306439eb858247","value":"Downloading: 100%"}},"1c9b26049cd0464ea54c787e809f5df0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_236e99f7b9504102a0f6861a93b50f3c","max":421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c5542cbeefb46b2bbd6fdc2087a15d8","value":421}},"f7e5976f3c8c4b458e6f259081a54dfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0060ca761399429ca6bf0e0a4fb4af14","placeholder":"​","style":"IPY_MODEL_a567846ea43e4cbb8658543d61c37844","value":" 421/421 [00:00&lt;00:00, 7.22kB/s]"}},"127f955811f14f9e902c81aedc6da9a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"594722e3b7734c56b32bcb022c83a6c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d03e25713f0434ead306439eb858247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"236e99f7b9504102a0f6861a93b50f3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c5542cbeefb46b2bbd6fdc2087a15d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0060ca761399429ca6bf0e0a4fb4af14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a567846ea43e4cbb8658543d61c37844":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2866451b46744bf8b617339735a52b20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf9b8ee1b76b4c0ba127282654629407","IPY_MODEL_43eecb9a7491462797e08ab1d5fd5538","IPY_MODEL_144cb81f127342db9f89eba44ca6b8c3"],"layout":"IPY_MODEL_eba9d07675ac4622a688a69b372af0de"}},"bf9b8ee1b76b4c0ba127282654629407":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8e8f5282a90478f97cbc455e1353397","placeholder":"​","style":"IPY_MODEL_96d950b0583f4f069f03b77bc38372b7","value":"Downloading: 100%"}},"43eecb9a7491462797e08ab1d5fd5538":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e34bf11cedf542db91d7092e96179b0a","max":1345000672,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be63489d15534fddbf18765d4ed360e4","value":1345000672}},"144cb81f127342db9f89eba44ca6b8c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b91deccc62e149889f083c1235c4a8da","placeholder":"​","style":"IPY_MODEL_4240b68d6cf54287897c75ff2b7578f8","value":" 1.25G/1.25G [01:04&lt;00:00, 27.6MB/s]"}},"eba9d07675ac4622a688a69b372af0de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8e8f5282a90478f97cbc455e1353397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96d950b0583f4f069f03b77bc38372b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e34bf11cedf542db91d7092e96179b0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be63489d15534fddbf18765d4ed360e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b91deccc62e149889f083c1235c4a8da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4240b68d6cf54287897c75ff2b7578f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c0668d341934edc8783d537081aabbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_902ae1eed3ef4db8b66fe0fa9e4e0366","IPY_MODEL_130324edb3a74b0b87afd829f7d0ec1f","IPY_MODEL_45e7af0ce8bf4024a92804d6d7e4281d"],"layout":"IPY_MODEL_72ebf0912fa849f88cb0b3b901eb71e1"}},"902ae1eed3ef4db8b66fe0fa9e4e0366":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9eb25e5f0d6942088d0e9d03ea1648ce","placeholder":"​","style":"IPY_MODEL_2d49bc97bdfe4cd8beee171a79286276","value":"Downloading: 100%"}},"130324edb3a74b0b87afd829f7d0ec1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4152618b54604d48b2ab98529e925aa2","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b4ab0d9ecbc4ad5adef1b199ef582ce","value":231508}},"45e7af0ce8bf4024a92804d6d7e4281d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14bf7b6d40e54f0cb3ead2d91dbdd18a","placeholder":"​","style":"IPY_MODEL_ae15019f25744613986e0217466d1785","value":" 226k/226k [00:00&lt;00:00, 926kB/s]"}},"72ebf0912fa849f88cb0b3b901eb71e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb25e5f0d6942088d0e9d03ea1648ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d49bc97bdfe4cd8beee171a79286276":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4152618b54604d48b2ab98529e925aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b4ab0d9ecbc4ad5adef1b199ef582ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14bf7b6d40e54f0cb3ead2d91dbdd18a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae15019f25744613986e0217466d1785":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"APNcea5IgoLQ","executionInfo":{"status":"ok","timestamp":1648206590368,"user_tz":-60,"elapsed":25063,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"6694078e-6b7c-4448-c4e1-aa7969f40df5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-Xuy6jRgzJg","executionInfo":{"status":"ok","timestamp":1648206601279,"user_tz":-60,"elapsed":10935,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"6caac28c-91d3-400e-b2a6-6c8707dc2070"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 31.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 43.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"],"metadata":{"id":"kYl4dFwWg9Be","executionInfo":{"status":"ok","timestamp":1648206613476,"user_tz":-60,"elapsed":8717,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv(\"/content/drive/MyDrive/Thesis/Data/Filled Datasets/Second dataset (Kaggle)/Raw/Constraint_Train.csv\",keep_default_na = False)\n","df_test = pd.read_csv(\"/content/drive/MyDrive/Thesis/Data/Filled Datasets/Second dataset (Kaggle)/Raw/english_test_with_labels.csv\", keep_default_na = False)\n","df_val = pd.read_csv(\"/content/drive/MyDrive/Thesis/Data/Filled Datasets/Second dataset (Kaggle)/Raw/Constraint_Val.csv\", keep_default_na = False)"],"metadata":{"id":"zfMNHiCfhA7k","executionInfo":{"status":"ok","timestamp":1648206616111,"user_tz":-60,"elapsed":2681,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df_train.head(n=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"jRvnQtHmjETx","executionInfo":{"status":"ok","timestamp":1648206616639,"user_tz":-60,"elapsed":544,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"72a98ae1-49a0-499c-fff1-e9ea86c8bb58"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label\n","0   1  The CDC currently reports 99031 deaths. In gen...  real\n","1   2  States reported 1121 deaths a small rise from ...  real\n","2   3  Politically Correct Woman (Almost) Uses Pandem...  fake"],"text/html":["\n","  <div id=\"df-68fcbf42-5174-413e-aaec-344b38aa834b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>The CDC currently reports 99031 deaths. In gen...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>States reported 1121 deaths a small rise from ...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n","      <td>fake</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68fcbf42-5174-413e-aaec-344b38aa834b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-68fcbf42-5174-413e-aaec-344b38aa834b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-68fcbf42-5174-413e-aaec-344b38aa834b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df_test.head(n=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"G2IVBe84jHDB","executionInfo":{"status":"ok","timestamp":1648206616643,"user_tz":-60,"elapsed":114,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"5c5dbba4-11be-4dcc-8078-19e43cdece60"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label\n","0   1  Our daily update is published. States reported...  real\n","1   2             Alfalfa is the only cure for COVID-19.  fake\n","2   3  President Trump Asked What He Would Do If He W...  fake"],"text/html":["\n","  <div id=\"df-962e67fc-4d81-40b5-a335-a0376f0dd20b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Our daily update is published. States reported...</td>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Alfalfa is the only cure for COVID-19.</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>President Trump Asked What He Would Do If He W...</td>\n","      <td>fake</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-962e67fc-4d81-40b5-a335-a0376f0dd20b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-962e67fc-4d81-40b5-a335-a0376f0dd20b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-962e67fc-4d81-40b5-a335-a0376f0dd20b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_val.head(n=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"Jlt1MFkQjI3_","executionInfo":{"status":"ok","timestamp":1648206616645,"user_tz":-60,"elapsed":100,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"c2307838-acee-4d80-b050-db2877ec9d78"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id                                              tweet label\n","0   1  Chinese converting to Islam after realising th...  fake\n","1   2  11 out of 13 people (from the Diamond Princess...  fake\n","2   3  COVID-19 Is Caused By A Bacterium, Not Virus A...  fake"],"text/html":["\n","  <div id=\"df-ccbed702-ae53-4853-97df-0c20533fa083\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Chinese converting to Islam after realising th...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>11 out of 13 people (from the Diamond Princess...</td>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>COVID-19 Is Caused By A Bacterium, Not Virus A...</td>\n","      <td>fake</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccbed702-ae53-4853-97df-0c20533fa083')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ccbed702-ae53-4853-97df-0c20533fa083 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ccbed702-ae53-4853-97df-0c20533fa083');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["for i in range(len(df_train['tweet'])): \n","  df_train.iloc[i,1] = str(df_train.iloc[i,1])\n","\n","for i in range(len(df_test['tweet'])): \n","  df_test.iloc[i,1] = str(df_test.iloc[i,1])\n","\n","for i in range(len(df_val['tweet'])): \n","  df_val.iloc[i,1] = str(df_val.iloc[i,1])"],"metadata":{"id":"uSvHlAe1hC5N","executionInfo":{"status":"ok","timestamp":1648206628790,"user_tz":-60,"elapsed":12242,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_text = df_train['tweet']\n","test_text = df_test['tweet']\n","train_labels = df_train['label']\n","test_labels = df_test['label']\n","val_text = df_val['tweet']\n","val_labels = df_val['label']\n","# we will use temp_text and temp_labels to create validation and test set\n","#val_text, train_text, val_labels, train_labels = train_test_split(train_text, train_labels, \n"," #                                                               random_state=2018, \n","  #                                                              test_size=0.5, \n","   #                                                             stratify=train_labels)"],"metadata":{"id":"7EaJXn51hFZF","executionInfo":{"status":"ok","timestamp":1648206628792,"user_tz":-60,"elapsed":32,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!pip3 install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6PTRiDFhZ_y","executionInfo":{"status":"ok","timestamp":1648206639387,"user_tz":-60,"elapsed":10622,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"463e6749-c470-46cb-98bb-0ccde22c03fc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-1.7.0.tar.gz (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 4.4 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=03a63b621c2d222eacd9f46da075d41f428e420d25a93ef5486a77f74d5c37a5\n","  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-1.7.0\n"]}]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer \n","\n","bertweet = AutoModel.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\", normalization=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187,"referenced_widgets":["b10e31783b804939a15bafc75b8f7789","b25b3ddd60df44bebe21b1b42027c43c","1c9b26049cd0464ea54c787e809f5df0","f7e5976f3c8c4b458e6f259081a54dfc","127f955811f14f9e902c81aedc6da9a4","594722e3b7734c56b32bcb022c83a6c6","1d03e25713f0434ead306439eb858247","236e99f7b9504102a0f6861a93b50f3c","0c5542cbeefb46b2bbd6fdc2087a15d8","0060ca761399429ca6bf0e0a4fb4af14","a567846ea43e4cbb8658543d61c37844","2866451b46744bf8b617339735a52b20","bf9b8ee1b76b4c0ba127282654629407","43eecb9a7491462797e08ab1d5fd5538","144cb81f127342db9f89eba44ca6b8c3","eba9d07675ac4622a688a69b372af0de","a8e8f5282a90478f97cbc455e1353397","96d950b0583f4f069f03b77bc38372b7","e34bf11cedf542db91d7092e96179b0a","be63489d15534fddbf18765d4ed360e4","b91deccc62e149889f083c1235c4a8da","4240b68d6cf54287897c75ff2b7578f8","0c0668d341934edc8783d537081aabbc","902ae1eed3ef4db8b66fe0fa9e4e0366","130324edb3a74b0b87afd829f7d0ec1f","45e7af0ce8bf4024a92804d6d7e4281d","72ebf0912fa849f88cb0b3b901eb71e1","9eb25e5f0d6942088d0e9d03ea1648ce","2d49bc97bdfe4cd8beee171a79286276","4152618b54604d48b2ab98529e925aa2","1b4ab0d9ecbc4ad5adef1b199ef582ce","14bf7b6d40e54f0cb3ead2d91dbdd18a","ae15019f25744613986e0217466d1785"]},"id":"ZbXsYfU2hLmM","executionInfo":{"status":"ok","timestamp":1648206712787,"user_tz":-60,"elapsed":73426,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"c8f0f03f-9a0f-4409-bc17-e646329d435a"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10e31783b804939a15bafc75b8f7789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2866451b46744bf8b617339735a52b20"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0668d341934edc8783d537081aabbc"}},"metadata":{}}]},{"cell_type":"markdown","source":["**Tokenization**"],"metadata":{"id":"B4ZBPCesiXAE"}},{"cell_type":"code","source":["max_seq_len = 50\n","\n","# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6ru2IKuiX-A","executionInfo":{"status":"ok","timestamp":1648206714592,"user_tz":-60,"elapsed":1840,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"6799fea3-5af9-4cf7-ef7d-8878587fbacd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["**Convert Integer Sequences to Tensors**"],"metadata":{"id":"SbkhtxPPkP8d"}},{"cell_type":"code","source":["test_labels = test_labels.map({'real':0,'fake':1})\n","train_labels = train_labels.map({'real':0,'fake':1})\n","val_labels = val_labels.map({'real':0,'fake':1})\n"],"metadata":{"id":"mUkRvPvlkTTH","executionInfo":{"status":"ok","timestamp":1648206714594,"user_tz":-60,"elapsed":21,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sySFJVxBmCNS","executionInfo":{"status":"ok","timestamp":1648038852991,"user_tz":-60,"elapsed":225,"user":{"displayName":"lowie holemans","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01122034015315685154"}},"outputId":"638eadde-e2dc-4541-ad5e-1ccbfc0aba1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       0\n","1       1\n","2       1\n","3       0\n","4       0\n","       ..\n","2135    0\n","2136    1\n","2137    0\n","2138    0\n","2139    0\n","Name: label, Length: 2140, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"metadata":{"id":"aAZwTQqWkVDY","executionInfo":{"status":"ok","timestamp":1648207173462,"user_tz":-60,"elapsed":313,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["**Create DataLoaders**"],"metadata":{"id":"Pi8TJ19yj4AJ"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"metadata":{"id":"Cr5jQqzXj6Rx","executionInfo":{"status":"ok","timestamp":1648207381926,"user_tz":-60,"elapsed":223,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["**Freeze BERTweet parameters**"],"metadata":{"id":"LZQnSM30mTWX"}},{"cell_type":"code","source":["for param in bertweet.parameters():\n","    param.requires_grad = False"],"metadata":{"id":"0kNMb-efmYR5","executionInfo":{"status":"ok","timestamp":1648207664931,"user_tz":-60,"elapsed":278,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["**Define Model Architecture**\n","\n","Here we should input our own classifier (I think)! Let's now use the one from the exemplificative notebook"],"metadata":{"id":"ot08kqCAmanT"}},{"cell_type":"code","source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      self.fc1 = nn.Linear(1024,512)\n","\n","      # sigmoid activatino function \n","      self.sigmoid = nn.Sigmoid()\n","      \n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(512,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n","      \n","      x = self.fc1(cls_hs)\n","\n","      x = self.relu(x)\n","\n","      x = self.dropout(x)\n","\n","      # output layer\n","      x = self.fc2(x)\n","\n","      x = self.softmax(x)\n","\n","      return x"],"metadata":{"id":"wKZF5V3Wmm5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pass the pre-trained BERTweet to our define architecture\n","model = BERT_Arch(bertweet)\n","\n","# push the model to GPU\n","model = model.to(device)"],"metadata":{"id":"DxqN5ZW_mdhg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 1e-4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qLg171e8icBn","executionInfo":{"status":"ok","timestamp":1648039442475,"user_tz":-60,"elapsed":223,"user":{"displayName":"lowie holemans","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01122034015315685154"}},"outputId":"68dfc273-0657-4def-8ba3-a6ae405f31d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["**Find Class weights**"],"metadata":{"id":"Wa4iwsFznnNp"}},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(train_labels), y=train_labels)\n","\n","print(class_wts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86FMtSc1noTN","executionInfo":{"status":"ok","timestamp":1648038882548,"user_tz":-60,"elapsed":217,"user":{"displayName":"lowie holemans","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01122034015315685154"}},"outputId":"4b074e19-2106-4a55-e2e7-15520ad71679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.95535714 1.04901961]\n"]}]},{"cell_type":"code","source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"metadata":{"id":"-BUo9ixtnrym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Fine-tune BERTweet**"],"metadata":{"id":"BjDdcAEpnuwh"}},{"cell_type":"code","source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"metadata":{"id":"Y48uheqtnwMI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      #elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"metadata":{"id":"DQKLmDdBn35q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Start model training**"],"metadata":{"id":"Lks1LdrHn5OA"}},{"cell_type":"code","source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3CVI6Vjn6jt","executionInfo":{"status":"ok","timestamp":1648041171540,"user_tz":-60,"elapsed":1725823,"user":{"displayName":"lowie holemans","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01122034015315685154"}},"outputId":"468c113f-3f63-4379-b7d8-5df62faa7002"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.402\n","Validation Loss: 0.262\n","\n"," Epoch 2 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.249\n","Validation Loss: 0.199\n","\n"," Epoch 3 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.210\n","Validation Loss: 0.177\n","\n"," Epoch 4 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.192\n","Validation Loss: 0.166\n","\n"," Epoch 5 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.174\n","Validation Loss: 0.165\n","\n"," Epoch 6 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.179\n","Validation Loss: 0.151\n","\n"," Epoch 7 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.162\n","Validation Loss: 0.153\n","\n"," Epoch 8 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.161\n","Validation Loss: 0.143\n","\n"," Epoch 9 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.165\n","Validation Loss: 0.162\n","\n"," Epoch 10 / 10\n","  Batch    50  of    201.\n","  Batch   100  of    201.\n","  Batch   150  of    201.\n","  Batch   200  of    201.\n","\n","Evaluating...\n","  Batch    50  of     67.\n","\n","Training Loss: 0.159\n","Validation Loss: 0.158\n"]}]},{"cell_type":"code","source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vni3qvAqqZfw","executionInfo":{"status":"ok","timestamp":1647800561498,"user_tz":-60,"elapsed":699,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"a48bbc8e-ef3d-4ebb-a1c7-c3521f9d2506"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["**Get predictions for test data**"],"metadata":{"id":"I8AWATnXqfWR"}},{"cell_type":"code","source":["# get predictions for test data\n","with torch.no_grad():\n","  preds = model(test_seq.to(device), test_mask.to(device))\n","  preds = preds.detach().cpu().numpy()"],"metadata":{"id":"2riz_8OrqiGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouObkTsdqeqh","executionInfo":{"status":"ok","timestamp":1647800577065,"user_tz":-60,"elapsed":16,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"c094c3f0-2e32-4825-c486-e8a8a011d2d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.92      0.91      1120\n","           1       0.91      0.89      0.90      1020\n","\n","    accuracy                           0.91      2140\n","   macro avg       0.91      0.91      0.91      2140\n","weighted avg       0.91      0.91      0.91      2140\n","\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc\n","# confusion matrix\n","print(confusion_matrix(test_y, preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLU9d8-drCz8","executionInfo":{"status":"ok","timestamp":1647800577066,"user_tz":-60,"elapsed":14,"user":{"displayName":"Hannes Verschueren","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqAOHnRWWbY68Otx493PM4MEnGL-2lbirzVfcywL0=s64","userId":"16576961637773447378"}},"outputId":"f9bd62ec-7622-4e3f-d3ee-d3031e5c79ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1031   89]\n"," [ 110  910]]\n"]}]}]}